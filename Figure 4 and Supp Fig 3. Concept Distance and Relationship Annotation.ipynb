{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Concept Distance vs Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many text mining algorithms for semantic annotation tokenize at the sentence level.  This script investigates the relationship annotations that may be missed when concept relationships are presented to annotators at the sentence-level, and inspects the effect of concept distance on the accuracy of the relationship annotation. To do this, the abstracts are tokenized at the sentence level to obtain an average per-sentence character count which can be used to estimate the concept distance at the sentence level.  Only concepts with known identifiers were analyzed as it would be more difficult to determine the positional location of a term in an abstract when the identifier is missing.\n",
    "\n",
    "Since discarding the concept annotation should not be affected by concept distance,relation annotations in concepts considered 'not broken' will be treated separately in this analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import random\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as mplot\n",
    "import m2c_rel_basic\n",
    "import relationship_dictionaries\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the relationship annotations data for only completed concept pairs, for which every concept has an associated identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savepath = 'data/'\n",
    "exppath = 'results/'\n",
    "all_completed_id_anns = read_csv(exppath+'all_completed_anns.txt', delimiter='\\t', header=0)\n",
    "all_completed_id_anns.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_hash_dict,redundant_response_dict,abbreviated_rels_dict,abbreviated_rels_dict_4_hash,concept_broken_dict,concept_not_broken_dict = relationship_dictionaries.load_RE_dictionaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the processed pubtator concept annotations and tokenized pmid data from the notebook on Investigating Concept Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conceptsource = 'concepts_anns_from_db.txt'\n",
    "pubsource = 'concept_anns_from_updated_pub_files.txt'\n",
    "concept_imported = read_csv(exppath+pubsource, delimiter='\\t', header=0)\n",
    "concept_imported.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "\n",
    "tokenize_sum = read_csv(exppath+'tokenized_pmids.txt',delimiter='\\t', header=0)\n",
    "tokenize_sum.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the QC'd annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "esample_df = m2c_rel_basic.get_QC_data(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the imported data for concept distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format the imported concept annotation data to include annotation end positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pmid                                  text     identifier type  offset  \\\n",
      "0  19067230                 hypertransaminasaemia  no identifier    d      19   \n",
      "1  19067230  congenital disorder of glycosylation        D018981    d      51   \n",
      "2  19067230                        Wilson disease        D006527    d     321   \n",
      "\n",
      "   length  endset  \n",
      "0      21      40  \n",
      "1      36      87  \n",
      "2      14     335  \n"
     ]
    }
   ],
   "source": [
    "concept_imported['endset'] = concept_imported['offset']+concept_imported['length']\n",
    "print(concept_imported.head(n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Copy slices/aggregations of the dataframe for downstream analysis without having to worry about the .loc exception\n",
    "cp_pair_counts = all_completed_id_anns.groupby(['pmid','concept_pair','reltype','refid1','refid2']).size().reset_index(name='completion_count')\n",
    "cp_pair_counts['pmid'] = cp_pair_counts['pmid'].astype(str)\n",
    "\n",
    "maxagree_result = cp_pair_counts.copy()\n",
    "pubtator_key = concept_imported.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pmid       concept_pair reltype   refid1   refid2  completion_count\n",
      "0  1299347  C095810_x_D008232     c_d  C095810  D008232                15\n",
      "1  1299347  D005944_x_D008232     c_d  D005944  D008232                15\n"
     ]
    }
   ],
   "source": [
    "print(maxagree_result.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   appear_no               cptext endset                  exact identifier  \\\n",
      "0          0  glycosylated lysine    365   glycosylated lysine     C039522   \n",
      "1          2  glycosylated lysine   1932   glycosylated lysine     C039522   \n",
      "\n",
      "   length  offset    pmid type  \n",
      "0      19     346  501285    c  \n",
      "1      19    1548  501285    c  \n"
     ]
    }
   ],
   "source": [
    "##import the annotations that were manually mapped after being dropped by pubtator (these are generated from the 'Mapping Dropped Concepts Script')\n",
    "dropped_anns_offsets_src = 'dropped_anns_offsets.txt'\n",
    "dropped_anns_offsets = read_csv(exppath+dropped_anns_offsets_src, delimiter='\\t', header=0)\n",
    "dropped_anns_offsets.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "dropped_anns_offsets['pmid'] = dropped_anns_offsets['pmid'].astype(str)\n",
    "dropped_anns_offsets['offset'] = dropped_anns_offsets['offset'].astype(int)\n",
    "dropped_anns_offsets['endset'] = dropped_anns_offsets['endset'].astype(str)\n",
    "dropped_anns_offsets_found = dropped_anns_offsets.loc[dropped_anns_offsets['offset']!=-1]\n",
    "dropped_anns_offsets_not_found = dropped_anns_offsets.loc[dropped_anns_offsets['offset']==-1]\n",
    "print(dropped_anns_offsets_found.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## for each pmid, pull out the concept pairs from the pubtator table\n",
    "## check the distance between concept1 and concept 2, and save the smallest distance\n",
    "\n",
    "l=0\n",
    "mindiff_list = []\n",
    "z = len(maxagree_result)\n",
    "\n",
    "while l<z:\n",
    "    testrefid1 = maxagree_result.iloc[l]['refid1']\n",
    "    testrefid2 = maxagree_result.iloc[l]['refid2']\n",
    "    testpmid = str(cp_pair_counts.iloc[l]['pmid'])\n",
    "    tmpdict = {'pmid':testpmid,\n",
    "               'refid1':testrefid1,\n",
    "               'refid2':testrefid2,\n",
    "               'concept_pair':maxagree_result.iloc[l]['concept_pair'],\n",
    "               'no_times_complete':maxagree_result.iloc[l]['completion_count']\n",
    "               }\n",
    "    i = 0\n",
    "    j = 0\n",
    "    offdiff = []\n",
    "    mindiff = 0\n",
    "    cp1 = pubtator_key.loc[(pubtator_key['pmid'].astype(str)==testpmid)&(pubtator_key['identifier']==testrefid1)]\n",
    "    cp2 = pubtator_key.loc[(pubtator_key['pmid'].astype(str)==testpmid)&(pubtator_key['identifier']==testrefid2)]\n",
    "    cp1_bkup = dropped_anns_offsets_found.loc[(dropped_anns_offsets_found['pmid']==testpmid)&(dropped_anns_offsets_found['identifier']==testrefid1)]\n",
    "    cp2_bkup = dropped_anns_offsets_found.loc[(dropped_anns_offsets_found['pmid']==testpmid)&(dropped_anns_offsets_found['identifier']==testrefid1)]\n",
    "    if (len(cp1) == 0) and (len(cp1_bkup)==0):\n",
    "        mindiff = -1\n",
    "        tmpdict['min_diff']=mindiff\n",
    "        tmpdict['notes']=testrefid1+' (cp1) removed not salvaged'\n",
    "        mindiff_list.append(tmpdict)\n",
    "        l=l+1    \n",
    "    elif (len(cp2) == 0) and (len(cp2_bkup)==0):\n",
    "        mindiff = -1\n",
    "        tmpdict['min_diff']=mindiff\n",
    "        tmpdict['notes']=testrefid2+' (cp2) removed not salvaged'\n",
    "        mindiff_list.append(tmpdict)\n",
    "        l=l+1     \n",
    "    else:\n",
    "        minset=set()\n",
    "        salvaged = False\n",
    "        cp1a_set = set(cp1['endset'].tolist()) ## create the set of offset and endset values for cp1 and cp2\n",
    "        if len(cp1a_set)==0:\n",
    "            cp1a_set = set(cp1_bkup['endset'].tolist()) ## create the set of offset and endset values for cp1 and cp2\n",
    "            salvaged = True\n",
    "        cp2a_set = set(cp2['offset'].tolist()) ## assuming that concept 1 appears before concept 2\n",
    "        if len(cp2a_set)==0:\n",
    "            cp2a_set = set(cp2_bkup['endset'].tolist()) ## create the set of offset and endset values for cp1 and cp2\n",
    "            salvaged = True\n",
    "        cp1b_set = set(cp1['offset'].tolist()) ## create the set of offset and endset values for cp1 and cp2\n",
    "        if len(cp1b_set)==0:\n",
    "            cp1b_set = set(cp1_bkup['endset'].tolist()) ## create the set of offset and endset values for cp1 and cp2\n",
    "            salvaged = True\n",
    "        cp2b_set = set(cp2['endset'].tolist()) ## assuming that concept 2 appears before concept 1\n",
    "        if len(cp2b_set)==0:\n",
    "            cp2b_set = set(cp2_bkup['endset'].tolist()) ## create the set of offset and endset values for cp1 and cp2\n",
    "            salvaged = True\n",
    "        #create a combination of values between the the endsets and offsets\n",
    "        if (len(cp1a_set)+len(cp1b_set)+len(cp2a_set)+len(cp2b_set) == 0) and salvaged==False:\n",
    "            tmpdict['notes']='dropped, not salvaged'\n",
    "            tmpdict['min_diff']='concept dropped'\n",
    "            mindiff_list.append(tmpdict)\n",
    "            n=n+1  \n",
    "        else:\n",
    "            if salvaged==True:\n",
    "                tmpdict['notes']='at least 1 dropped, salvaged'\n",
    "            else:\n",
    "                tmpdict['notes']='none dropped, not salvaged'\n",
    "            tmppdf1 = pandas.DataFrame([(endset,offset) for endset in cp1a_set for offset in cp2a_set]) #cp1 first then cp2\n",
    "            tmppdf2 = pandas.DataFrame([(endset,offset) for offset in cp1b_set for endset in cp2b_set]) #cp2 first then cp1\n",
    "            tmppdf1['c1_first'] = tmppdf1[1].astype(int)-tmppdf1[0].astype(int)\n",
    "            tmppdf2['c2_first'] = tmppdf2[1].astype(int)-tmppdf2[0].astype(int)\n",
    "            mindiff1 = tmppdf1.loc[tmppdf1['c1_first']>0]\n",
    "            mindiff2 = tmppdf2.loc[tmppdf2['c2_first']>0]\n",
    "            if len(mindiff1)>0:\n",
    "                minset.add(mindiff1.c1_first.min())\n",
    "            if len(mindiff2)>0:\n",
    "                minset.add(mindiff2.c2_first.min())\n",
    "            if len(minset)>1:\n",
    "                mindiff = min(minset)\n",
    "            elif len(minset)==1:\n",
    "                mindiff = list(minset)[0]\n",
    "            else:\n",
    "                mindiff = -1\n",
    "            tmpdict['min_diff']=str(mindiff)\n",
    "            mindiff_list.append(tmpdict)\n",
    "            l=l+1\n",
    "\n",
    "mindiff_df = pandas.DataFrame(mindiff_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept pairs to check for concept distance:  1009\n",
      "concept pairs less unsalvageable concepts:  699\n",
      "        concept_pair min_diff  no_times_complete                       notes  \\\n",
      "0  C095810_x_D008232      322                 15  none dropped, not salvaged   \n",
      "1  D005944_x_D008232      562                 15  none dropped, not salvaged   \n",
      "\n",
      "      pmid   refid1   refid2  \n",
      "0  1299347  C095810  D008232  \n",
      "1  1299347  D005944  D008232  \n"
     ]
    }
   ],
   "source": [
    "## remove the unsalvaged annotations from the concept distance calculations\n",
    "concept_distance = mindiff_df.loc[(mindiff_df['min_diff']!=-1)&(mindiff_df['min_diff']!='-1')]\n",
    "print('concept pairs to check for concept distance: ',len(maxagree_result))\n",
    "print('concept pairs less unsalvageable concepts: ',len(concept_distance))\n",
    "print(concept_distance.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pmid refid1   refid2                         notes min_diff  \\\n",
      "57  10068747   5443  C536008  at least 1 dropped, salvaged     1218   \n",
      "58  10068747   5443  D000309  at least 1 dropped, salvaged      279   \n",
      "\n",
      "    sent_diff   word_diff                    cpmid  \n",
      "57  14.024180  189.326425  10068747_5443_x_C536008  \n",
      "58   3.212435   43.367876  10068747_5443_x_D000309  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ginger\\Anaconda3\\envs\\py3bioc\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#### Merge the concept distance data with the tokenized abstract data\n",
    "concept_distance['pmid'] = concept_distance['pmid'].astype(int)\n",
    "tokenize_sum['pmid'] = tokenize_sum['pmid'].astype(int)\n",
    "concept_dist_df = concept_distance.merge(tokenize_sum,on='pmid', how='left')\n",
    "concept_dist_df['sent_diff'] = concept_dist_df['min_diff'].astype(float).div(concept_dist_df['char_p_sent'])\n",
    "concept_dist_df['word_diff'] = concept_dist_df['min_diff'].astype(float).div(concept_dist_df['char_p_word'])\n",
    "#print(concept_dist_df.head(n=2))\n",
    "\n",
    "concept_dist_to_check = concept_dist_df[['pmid','refid1','refid2','notes','min_diff','sent_diff','word_diff']].copy()\n",
    "concept_dist_to_check['cpmid']=concept_dist_to_check['pmid'].astype(str).str.cat(concept_dist_to_check['refid1'].astype(str).str.cat(concept_dist_to_check['refid2'], sep='_x_'), sep='_')\n",
    "concept_dist_to_check.sort_values(['cpmid','min_diff'],ascending=(True,True),inplace=True)\n",
    "print(concept_dist_to_check.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze for Accuracy relative to the QC'd set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note which cpmids should vs shouldn't be marked as broken; note which concept pairs were determined to have 'no relationship'; and get the cpmids from the remaining QC'd annotations and create the test set from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "esample_df['conclusion'].replace(abbreviated_rels_dict_4_hash, inplace=True)\n",
    "esample_df['conclusion'].replace(concept_broken_dict, inplace=True)\n",
    "not_broken = esample_df.loc[esample_df['conclusion']!='concept_broken'].copy()\n",
    "\n",
    "no_relation = esample_df.loc[esample_df['conclusion'].str.contains('unrelated')].copy()\n",
    "related = esample_df.loc[(esample_df['conclusion']!='concept_broken')&\n",
    "                         (~esample_df['conclusion'].str.contains('unrelated'))].copy()\n",
    "                                                                   \n",
    "test_set_cpmids = set(esample_df['cpmid'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cpmids to pull the user annotations for quality checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_ref_set = all_completed_id_anns.loc[all_completed_id_anns['cpmid'].isin(test_set_cpmids)].copy()\n",
    "total_ref_set['evtype'].replace(abbreviated_rels_dict_4_hash, inplace=True)\n",
    "total_ref_set['evtype'].replace(concept_broken_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the inclusion of the reference cpmids in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of Non-broken QC annotations:  116\n",
      "number of QC cpmids in the tokenized abstract set 80\n"
     ]
    }
   ],
   "source": [
    "print('number of Non-broken QC annotations: ',len(test_set_cpmids))\n",
    "tokenize_test_set = concept_dist_to_check.loc[concept_dist_to_check['cpmid'].isin(test_set_cpmids)]\n",
    "print('number of QC cpmids in the tokenized abstract set', len(tokenize_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample the results to determine how number of voters (n) affects accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repetition: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-de2e3a557f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[1;31m## Groupby response and get biggest and next biggest value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         \u001b[0mref_sample_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mref_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cpmid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'evtype'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'counts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                         \u001b[0mref_sample_size\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'counts'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0mfirst_most\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mref_sample_size\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'counts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ginger\\Anaconda3\\envs\\py3bioc\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, name, inplace)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__unicode__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ginger\\Anaconda3\\envs\\py3bioc\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   3024\u001b[0m                     \u001b[0mlevel_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_casted_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m                         \u001b[0mnew_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ginger\\Anaconda3\\envs\\py3bioc\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   2509\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m         self._data.insert(loc, column, value,\n\u001b[0;32m-> 2511\u001b[0;31m                           allow_duplicates=allow_duplicates)\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ginger\\Anaconda3\\envs\\py3bioc\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3787\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3788\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\ginger\\Anaconda3\\envs\\py3bioc\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   4433\u001b[0m         \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4434\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnumnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4435\u001b[0;31m         \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4436\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnumnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4437\u001b[0m         \u001b[0mslobj2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### Sampling the responses and putting into a dataframe, 10 iterations per n per cpmid\n",
    "#### repeating the sampling 5 times to stabilize the results\n",
    "#### This is the slowest part of the code; hence, a print statement has been left in so you know it's working\n",
    "n=1\n",
    "majority_response=[]\n",
    "j=0\n",
    "problem_cpmids = []\n",
    "cp_dist_issues = []\n",
    "\n",
    "while j<5:\n",
    "    i=0\n",
    "    print('repetition:',j)\n",
    "    while i<10:\n",
    "        n=1\n",
    "        while n<16:\n",
    "            for each_cpmid in test_set_cpmids:\n",
    "                result_dict = {}\n",
    "                result_dict['repetition'] = j\n",
    "                result_dict['iteration'] = i\n",
    "                result_dict['cpmid'] = each_cpmid\n",
    "                result_dict['n'] = n\n",
    "                try:\n",
    "                    tmp_df = total_ref_set.loc[total_ref_set['cpmid']==each_cpmid]\n",
    "                    user_set = set(tmp_df['user_id'].tolist())\n",
    "                except: \n",
    "                    problem_cpmids.append(each_cpmid)\n",
    "                    user_set=set()                   \n",
    "                if n<=len(user_set):\n",
    "                    user_sample = random.sample(user_set, n)\n",
    "                    ref_sample = tmp_df.loc[tmp_df['user_id'].isin(user_sample)]\n",
    "                    if n == 1:\n",
    "                        result_dict['response'] = ref_sample.iloc[0]['evtype']\n",
    "                        result_dict['majority?'] = 'yes'\n",
    "                        result_dict['tie?'] = 'no'\n",
    "                        result_dict['result_selection'] = 'single_vote'\n",
    "                    else:\n",
    "                        ## Groupby response and get biggest and next biggest value    \n",
    "                        ref_sample_size = ref_sample.groupby(['cpmid','evtype']).size().reset_index(name='counts')\n",
    "                        ref_sample_size.sort_values('counts', ascending=False, inplace=True)\n",
    "                        first_most = ref_sample_size.iloc[0]['counts']\n",
    "                        try:\n",
    "                            sec_most = ref_sample_size.iloc[1]['counts'] ##if this works, results are not unanimous\n",
    "                            if first_most > sec_most: ## If there is a majority\n",
    "                                result_dict['majority?'] = 'simple_majority'\n",
    "                                result_dict['result_selection'] = 'majority'\n",
    "                                result_dict['response'] = ref_sample_size.iloc[0]['evtype']\n",
    "                                result_dict['tie?'] = 'no'\n",
    "                            else: ## else it's a tie\n",
    "                                result_dict['majority?'] = 'no_majority'\n",
    "                                result_dict['result_selection'] = 'random'\n",
    "                                if len(ref_sample_size)==2: ## check if full tie\n",
    "                                    rand_option = random.randint(0, 1)\n",
    "                                    result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                    result_dict['tie?'] = 'two_way'\n",
    "                                elif (len(ref_sample_size) > 2) & (sec_most > ref_sample_size.iloc[3]['counts']): #check if majority tied\n",
    "                                    rand_option = random.randint(0, 1)\n",
    "                                    result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                    result_dict['tie?'] = 'top_two_way'\n",
    "                                elif (len(ref_sample_size) > 2) & (sec_most == ref_sample_size.iloc[3]['counts']): #check for 3-way tie                      \n",
    "                                    rand_option = random.randint(0, 2)\n",
    "                                    result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                    result_dict['tie?'] = '3_way'\n",
    "                                else:    \n",
    "                                    rand_option = random.randint(0, len(ref_sample_size))\n",
    "                                    result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                    result_dict['tie?'] = 'other'\n",
    "                        except: ## Scenario: results are unanimous\n",
    "                            result_dict['majority?'] = 'unanimous'\n",
    "                            result_dict['response'] = ref_sample_size.iloc[0]['evtype']\n",
    "                            result_dict['tie?'] = 'no'\n",
    "                            result_dict['result_selection'] = 'majority'\n",
    "                else:\n",
    "                    result_dict['majority?'] = 'n/a'\n",
    "                    result_dict['response'] = 'not_enough'\n",
    "                    result_dict['tie?'] = 'n/a'\n",
    "                    result_dict['result_selection'] = 'n/a' \n",
    "                ## check how well user response matched expert response\n",
    "                tmp_edf = esample_df.loc[esample_df['cpmid']==each_cpmid]           \n",
    "                test_response = result_dict.get('response')\n",
    "                expert_response = tmp_edf['conclusion'].iloc[0]\n",
    "                if test_response=='not_enough':\n",
    "                    result_dict['expert_match?'] = 'n/a'\n",
    "                elif test_response == expert_response:\n",
    "                    result_dict['expert_match?'] = 'yes'\n",
    "                else:\n",
    "                    result_dict['expert_match?'] = 'no'\n",
    "                majority_response.append(result_dict) \n",
    "            n = n+1\n",
    "        i=i+1\n",
    "    j=j+1\n",
    "    \n",
    "\n",
    "majority_df = pandas.DataFrame(majority_response)\n",
    "\n",
    "print(majority_df.head(n=5))\n",
    "#majority_df.to_csv(exppath+'accuracy_for_concept_distance.txt',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#majority_df = read_csv(exppath+'accuracy_for_concept_distance.txt',delimiter='\\t',header=0)\n",
    "#majority_df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "#print(majority_df.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### calculate accuracy on a per-cpmid basis\n",
    "\n",
    "#analysis_df = majority_df.loc[majority_df['repetition']==3]\n",
    "#response_matrix = analysis_df.groupby(['cpmid','repetition','n','expert_match?']).size().reset_index(name='counts')\n",
    "\n",
    "response_matrix = majority_df.groupby(['cpmid','repetition','n','expert_match?']).size().reset_index(name='counts')\n",
    "\n",
    "## remove the n/a responses (this is usually when k exceeds sample due to removal of tester account data)\n",
    "response_matrix_less_missing = response_matrix.loc[response_matrix['expert_match?']!='n/a']\n",
    "total_captured = response_matrix_less_missing.groupby(['cpmid','repetition','n'])['counts'].sum().reset_index(name='totals')\n",
    "\n",
    "## Merge tables to be able to do calculations and obtain total attempts\n",
    "tmpresults_df = response_matrix.merge(total_captured,on=(['cpmid','repetition','n']))\n",
    "\n",
    "## Calculate accuracy (True Positive/Total) and inaccuracy (Incorrect Response/Total)\n",
    "tmpresults_df['ratios'] = tmpresults_df['counts']/tmpresults_df['totals']\n",
    "#print(tmpresults_df)\n",
    "\n",
    "## Since accuracy only counts true positives and total attempts, keep only the true positive data\n",
    "accuracy_df = tmpresults_df.loc[tmpresults_df['expert_match?']=='yes']\n",
    "\n",
    "## Calculate the mean, max, median, and sem of the accuracy data frame by aggregating over the 10 iterations\n",
    "mean_accuracy = accuracy_df.groupby(['cpmid','n']).ratios.mean().reset_index(name='avg_accuracy')\n",
    "max_accuracy = accuracy_df.groupby(['cpmid','n']).ratios.max().reset_index(name='max_accuracy')\n",
    "median_accuracy = accuracy_df.groupby(['cpmid','n']).ratios.median().reset_index(name='median_accuracy')\n",
    "mean_error = accuracy_df.groupby(['cpmid','n']).ratios.sem().reset_index(name='std_error')\n",
    "    \n",
    "stats_result = mean_accuracy.merge(max_accuracy.merge(median_accuracy.merge(mean_error, on=(['cpmid','n']), how='left'), on=(['cpmid','n']), how='left'), on=(['cpmid','n']), how='left')\n",
    "print(stats_result.head(n=2))\n",
    "#stats_result.to_csv(exppath+'accuracy_stats_for_concept_distance.txt',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stats_result = read_csv(exppath+'accuracy_stats_for_concept_distance.txt',delimiter='\\t',header=0)\n",
    "#stats_result.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        cpmid  n  avg_accuracy  max_accuracy  median_accuracy  \\\n",
      "0  10429369_D009711_x_D018981  1          0.86           0.9              0.9   \n",
      "1  10429369_D009711_x_D018981  2          0.82           1.0              0.9   \n",
      "\n",
      "   std_error  pmid refid1 refid2 notes min_diff  sent_diff  word_diff  \n",
      "0   0.024495    -1     -1     -1    -1       -1       -1.0       -1.0  \n",
      "1   0.073485    -1     -1     -1    -1       -1       -1.0       -1.0  \n"
     ]
    }
   ],
   "source": [
    "## Merge the concept distance table with the annotations table to get the user response ratios and look at distance vs accuracy\n",
    "cp_accuracy_distance = stats_result.merge(concept_dist_to_check,on='cpmid',how='left').fillna(-1)\n",
    "cp_accuracy_distance['pmid']=cp_accuracy_distance['pmid'].astype(int)\n",
    "#print(set(cp_accuracy_distance['sent_diff'].loc[cp_accuracy_distance['sent_diff']<1].tolist()))\n",
    "print(cp_accuracy_distance.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Do the same analysis for broken annotations as a control to see if there's a difference between cp distance and accuracy when annotations are broken vs not broken (broken, should be all over the place), not broken (distance may affect accuracy)\n",
    "Plot out accuracy, distance, K for broken vs not broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "## Split the results between annotations which should be marked as broken and ones that should not\n",
    "not_broken_results = cp_accuracy_distance.loc[(cp_accuracy_distance['cpmid'].isin(not_broken['cpmid'].tolist()))&(cp_accuracy_distance['sent_diff']!=-1)]\n",
    "print(len(not_broken_results))\n",
    "broken_results = cp_accuracy_distance.loc[(~cp_accuracy_distance['cpmid'].isin(not_broken['cpmid'].tolist()))&(cp_accuracy_distance['sent_diff']!=-1)]\n",
    "print(len(broken_results))\n",
    "nb_missing = cp_accuracy_distance.loc[(cp_accuracy_distance['cpmid'].isin(not_broken['cpmid'].tolist()))&(cp_accuracy_distance['sent_diff']==-1)]\n",
    "b_missing = cp_accuracy_distance.loc[(~cp_accuracy_distance['cpmid'].isin(not_broken['cpmid'].tolist()))&(cp_accuracy_distance['sent_diff']==-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "568\n"
     ]
    }
   ],
   "source": [
    "unrelated = cp_accuracy_distance.loc[(cp_accuracy_distance['cpmid'].isin(no_relation['cpmid'].tolist()))&(cp_accuracy_distance['sent_diff']!=-1)]\n",
    "print(len(unrelated))\n",
    "related = cp_accuracy_distance.loc[(cp_accuracy_distance['cpmid'].isin(related['cpmid'].tolist()))&(cp_accuracy_distance['sent_diff']!=-1)]\n",
    "print(len(related))\n",
    "unrelated_missing = cp_accuracy_distance.loc[(cp_accuracy_distance['cpmid'].isin(no_relation['cpmid'].tolist()))&(cp_accuracy_distance['sent_diff']==-1)]\n",
    "related_missing = cp_accuracy_distance.loc[(cp_accuracy_distance['cpmid'].isin(related['cpmid'].tolist()))&(cp_accuracy_distance['sent_diff']==-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Accuracy vs distance for just concepts which were not considered broken only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = mplot.subplots(3, 5,figsize=(15,6))\n",
    "i=0\n",
    "while i<15:\n",
    "    j=i+1\n",
    "    tmpplotdata = not_broken_results[['avg_accuracy','max_accuracy','n','cpmid','sent_diff','word_diff']].loc[not_broken_results['n']==j].copy()\n",
    "    tmpnb_missing = nb_missing[['avg_accuracy','max_accuracy','n','cpmid','sent_diff','word_diff']].loc[nb_missing['n']==j].copy()\n",
    "    \n",
    "    if i>14:\n",
    "        break\n",
    "    elif i <= 4:\n",
    "        gridx=0\n",
    "        gridy=i\n",
    "    elif 4 < i & i <= 9:\n",
    "        gridx=1\n",
    "        gridy=i-5\n",
    "    else:\n",
    "        gridx=2\n",
    "        gridy=i-10\n",
    "    axarr[gridx, gridy].scatter(x=tmpplotdata[\"sent_diff\"], y=tmpplotdata[\"avg_accuracy\"], color=\"green\", alpha=0.5)\n",
    "    axarr[gridx, gridy].set_xlim(-2, 10)\n",
    "    axarr[gridx, gridy].scatter(x=tmpnb_missing[\"sent_diff\"], y=tmpnb_missing[\"avg_accuracy\"], color=\"grey\", alpha=0.5)\n",
    "    axarr[gridx, gridy].set_title('n='+str(j),fontsize=15)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Fine-tune figure; hide x ticks for top plots and y ticks for right plots\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[0, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[1, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[2, :]], visible=True,fontsize=15)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 0]], visible=True,fontsize=15)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 1]], visible=False)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 2]], visible=False)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 3]], visible=False)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 4]], visible=False)\n",
    "mplot.show()\n",
    "#mplot.savefig(exppath+'concept_distance_lg_size.png', bbox_inches='tight', dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Supplemental Figure\n",
    "Check to see if there's a different distribution for concepts which were deemed to be unrelated vs 'non-broken' concepts that were deemed to be related.  Since there are only 11 cpmids in the quality checked set deemed to be unrelated, this is extra step is not included in the main analysis but instead treated as a supplemental analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = mplot.subplots(9, 5,figsize=(15,15))\n",
    "i=0\n",
    "while i<15:\n",
    "    j=i+1\n",
    "    tmpplotdata = related[['avg_accuracy','max_accuracy','n','cpmid','sent_diff','word_diff']].loc[related['n']==j].copy()\n",
    "    tmpunrdata = unrelated[['avg_accuracy','max_accuracy','n','cpmid','sent_diff','word_diff']].loc[unrelated['n']==j].copy()\n",
    "    tmpbrkdata = broken_results[['avg_accuracy','max_accuracy','n','cpmid','sent_diff','word_diff']].loc[broken_results['n']==j].copy()\n",
    "    tmpb_missing = b_missing[['avg_accuracy','max_accuracy','n','cpmid','sent_diff','word_diff']].loc[b_missing['n']==j].copy()\n",
    "    tmpnb_missing = related_missing[['avg_accuracy','max_accuracy','n','cpmid','sent_diff','word_diff']].loc[related_missing['n']==j].copy()\n",
    "    tmpu_missing = unrelated_missing[['avg_accuracy','max_accuracy','n','cpmid','sent_diff','word_diff']].loc[unrelated_missing['n']==j].copy()\n",
    "    \n",
    "    if i>14:\n",
    "        break\n",
    "    elif i <= 4:\n",
    "        gridx=0\n",
    "        gridy=i\n",
    "    elif 4 < i & i <= 9:\n",
    "        gridx=1\n",
    "        gridy=i-5\n",
    "    else:\n",
    "        gridx=2\n",
    "        gridy=i-10\n",
    "    axarr[gridx, gridy].scatter(x=tmpplotdata[\"sent_diff\"], y=tmpplotdata[\"avg_accuracy\"], color=\"green\", alpha=0.5)\n",
    "    axarr[gridx, gridy].scatter(x=tmpnb_missing[\"sent_diff\"], y=tmpnb_missing[\"avg_accuracy\"], color=\"grey\", alpha=0.5)\n",
    "    axarr[gridx, gridy].set_xlim(-2, 10)\n",
    "    axarr[gridx, gridy].set_title('n='+str(j))\n",
    "    axarr[(gridx+3), gridy].scatter(x=tmpunrdata[\"sent_diff\"], y=tmpunrdata[\"avg_accuracy\"], color=\"blue\", alpha=0.5)\n",
    "    axarr[gridx+3, gridy].scatter(x=tmpu_missing[\"sent_diff\"], y=tmpu_missing[\"avg_accuracy\"], color=\"grey\", alpha=0.5)\n",
    "    axarr[gridx+3, gridy].set_xlim(-2, 10)\n",
    "    axarr[(gridx+3), gridy].set_title('n='+str(j))\n",
    "    axarr[(gridx+6), gridy].scatter(x=tmpbrkdata[\"sent_diff\"], y=tmpbrkdata[\"avg_accuracy\"], color=\"red\", alpha=0.5)\n",
    "    axarr[gridx+6, gridy].scatter(x=tmpb_missing[\"sent_diff\"], y=tmpb_missing[\"avg_accuracy\"], color=\"grey\", alpha=0.5)\n",
    "    axarr[gridx+6, gridy].set_xlim(-2, 10)\n",
    "    axarr[(gridx+6), gridy].set_title('n='+str(j))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Fine-tune figure; hide x ticks for top plots and y ticks for right plots\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[0, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[1, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[2, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[3, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[4, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[5, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[6, :]], visible=False)\n",
    "mplot.setp([a.get_xticklabels() for a in axarr[7, :]], visible=False)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 1]], visible=False)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 2]], visible=False)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 3]], visible=False)\n",
    "mplot.setp([a.get_yticklabels() for a in axarr[:, 4]], visible=False)\n",
    "mplot.show()\n",
    "#mplot.savefig(exppath+'concept_distance_sup.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
