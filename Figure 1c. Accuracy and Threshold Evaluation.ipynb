{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Relationship Annotation Accuracy Based on a QC'd Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the evaluation of user annotations in comparison of the randomly sampled set of completed tasks that have been manually annotated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import modules and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import m2c_rel_basic\n",
    "import relationship_dictionaries\n",
    "import random\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as mplot\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the relationship annotations data for only completed concept pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savepath = 'data/'\n",
    "exppath = 'results/'\n",
    "all_completed_anns = read_csv(exppath+'all_completed_anns.txt', delimiter='\\t', header=0)\n",
    "all_completed_anns.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Quality Curated Sample Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "esample_df = m2c_rel_basic.get_QC_data(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dictionaries for translating hashed responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_hash_dict,redundant_response_dict,abbreviated_rels_dict,abbreviated_rels_dict_4_hash,concept_broken_dict,concept_not_broken_dict = relationship_dictionaries.load_RE_dictionaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the user annotations relative to the quality curated annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pull the annotations marked 'broken' during QC'ing into a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_broken = esample_df.loc[esample_df['conclusion']=='concept_broken']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pull the cpmids (concept pair pmid hashed identifiers) that were QC'd into a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_cpmids = set(esample_df['cpmid'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cpmids from the set of annotations that were QC'd and use the cpmids from the QC'd set to pull all user annotations for the same cpmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_cpmids = set(expert_cpmids)\n",
    "total_ref_set = all_completed_anns.loc[all_completed_anns['cpmid'].isin(test_set_cpmids)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviate the user responses for ease of viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_ref_set['evtype'].replace(abbreviated_rels_dict_4_hash, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove distinction between C1 broken and C2 broken since it's technically possible for both to be true AND because it's not important to distinguish it in this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   kind             ann_date  user_id         evtype reltype      pmid  \\\n",
      "8    re  2016-05-24 06:54:49      364  g_unrelated_d     g_d  11353896   \n",
      "14   re  2016-05-24 07:23:43      364   g_mutation_d     g_d  16970037   \n",
      "\n",
      "        concept_created      concept_updated refid1   refid2    concept_pair  \\\n",
      "8   2015-05-21 17:54:48  2015-05-21 17:54:48   4158  D004931  4158_x_D004931   \n",
      "14  2015-05-21 17:54:44  2015-05-21 17:54:44   8086  D009461  8086_x_D009461   \n",
      "\n",
      "   refid1_type refid2_type  user_count  relation_count  test_completions  \\\n",
      "8            g           d        29.0            14.0               1.0   \n",
      "14           g           d        27.0            19.0               3.0   \n",
      "\n",
      "    true_responses  response_ratio                    cpmid  \n",
      "8             28.0        0.500000  11353896_4158_x_D004931  \n",
      "14            24.0        0.791667  16970037_8086_x_D009461  \n"
     ]
    }
   ],
   "source": [
    "total_ref_set['evtype'].replace(concept_broken_dict, inplace=True)\n",
    "esample_df['conclusion'].replace(concept_broken_dict, inplace=True)\n",
    "print(total_ref_set.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly subsample the user annotations to determine how worker number (n) relates to agreement with the quality-checked results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the responses and put the results into a dataframe, 10 iterations per n per cpmid. \n",
    "Note that this is the slowest part of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n=1\n",
    "majority_response=[]\n",
    "\n",
    "i=0\n",
    "while i<10:\n",
    "    n=1\n",
    "    while n<16:\n",
    "        for each_cpmid in test_set_cpmids:\n",
    "            result_dict = {}\n",
    "            result_dict['iteration'] = i\n",
    "            result_dict['cpmid'] = each_cpmid\n",
    "            result_dict['n'] = n\n",
    "            tmp_df = total_ref_set.loc[total_ref_set['cpmid']==each_cpmid]\n",
    "            user_set = set(tmp_df['user_id'].tolist())\n",
    "            if n<=len(user_set):\n",
    "                user_sample = random.sample(user_set, n)\n",
    "                ref_sample = tmp_df.loc[tmp_df['user_id'].isin(user_sample)]\n",
    "                if n == 1:\n",
    "                    result_dict['response'] = ref_sample.iloc[0]['evtype']\n",
    "                    result_dict['majority?'] = 'yes'\n",
    "                    result_dict['tie?'] = 'no'\n",
    "                    result_dict['result_selection'] = 'single_vote'\n",
    "                else:\n",
    "                    ## Groupby response and get biggest and next biggest value    \n",
    "                    ref_sample_size = ref_sample.groupby(['cpmid','evtype']).size().reset_index(name='counts')\n",
    "                    ref_sample_size.sort_values('counts', ascending=False, inplace=True)\n",
    "                    first_most = ref_sample_size.iloc[0]['counts']\n",
    "                    try:\n",
    "                        sec_most = ref_sample_size.iloc[1]['counts'] ##if this works, results are not unanimous\n",
    "                        if first_most > sec_most: ## If there is a majority\n",
    "                            result_dict['majority?'] = 'simple_majority'\n",
    "                            result_dict['result_selection'] = 'majority'\n",
    "                            result_dict['response'] = ref_sample_size.iloc[0]['evtype']\n",
    "                            result_dict['tie?'] = 'no'\n",
    "                        else: ## else it's a tie\n",
    "                            result_dict['majority?'] = 'no_majority'\n",
    "                            result_dict['result_selection'] = 'random'\n",
    "                            if len(ref_sample_size)==2: ## check if full tie\n",
    "                                rand_option = random.randint(0, 1)\n",
    "                                result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                result_dict['tie?'] = 'two_way'\n",
    "                            elif (len(ref_sample_size) > 2) & (sec_most > ref_sample_size.iloc[3]['counts']): #check if majority tied\n",
    "                                rand_option = random.randint(0, 1)\n",
    "                                result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                result_dict['tie?'] = 'top_two_way'\n",
    "                            elif (len(ref_sample_size) > 2) & (sec_most == ref_sample_size.iloc[3]['counts']): #check for 3-way tie                      \n",
    "                                rand_option = random.randint(0, 2)\n",
    "                                result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                result_dict['tie?'] = '3_way'\n",
    "                            else:    \n",
    "                                rand_option = random.randint(0, len(ref_sample_size))\n",
    "                                result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                result_dict['tie?'] = 'other'\n",
    "                    except: ## Scenario: results are unanimous\n",
    "                        result_dict['majority?'] = 'unanimous'\n",
    "                        result_dict['response'] = ref_sample_size.iloc[0]['evtype']\n",
    "                        result_dict['tie?'] = 'no'\n",
    "                        result_dict['result_selection'] = 'majority'\n",
    "            else:\n",
    "                result_dict['majority?'] = 'n/a'\n",
    "                result_dict['response'] = 'not_enough'\n",
    "                result_dict['tie?'] = 'n/a'\n",
    "                result_dict['result_selection'] = 'n/a' \n",
    "            ## check how well user response matched expert response\n",
    "            tmp_edf = esample_df.loc[esample_df['cpmid']==each_cpmid]           \n",
    "            test_response = result_dict.get('response')\n",
    "            expert_response = tmp_edf['conclusion'].iloc[0]\n",
    "            if test_response=='not_enough':\n",
    "                result_dict['expert_match?'] = 'n/a'\n",
    "            elif test_response == expert_response:\n",
    "                result_dict['expert_match?'] = 'yes'\n",
    "            else:\n",
    "                result_dict['expert_match?'] = 'no'\n",
    "            majority_response.append(result_dict) \n",
    "        n = n+1\n",
    "    i=i+1\n",
    "   \n",
    "\n",
    "majority_df = pandas.DataFrame(majority_response)\n",
    "\n",
    "print(majority_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#majority_df.to_csv(exppath+'raw_random_accuracy_results.txt',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#majority_df = read_csv(exppath+'raw_random_accuracy_results.txt',delimiter='\\t',header=0)\n",
    "#majority_df.drop('Unnamed: 0',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the resulting data, grouping by iteration and threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of expert_match (true positive) vs total number of responses (true positive plus incorrect response) \n",
    "This gives total number of answers that matched vs didn't match the QC'd result for the whole QC cpmid set at every level of n, for each repetition and iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_matrix = majority_df.groupby(['iteration','n','expert_match?']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the n/a responses (this is usually when n exceeds sample due to removal of tester account data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response_matrix_less_missing = response_matrix.loc[response_matrix['expert_match?']!='n/a']\n",
    "total_captured = response_matrix_less_missing.groupby(['iteration','n'])['counts'].sum().reset_index(name='totals')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge tables to be able to do calculations and obtain total attempts, then calculate accuracy (True Positive/Total) and inaccuracy (Incorrect Response/Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmpresults_df = response_matrix.merge(total_captured,on=(['iteration','n']))\n",
    "tmpresults_df['ratios'] = tmpresults_df['counts']/tmpresults_df['totals']\n",
    "#print(tmpresults_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since accuracy only counts true positives and total attempts, keep only the true positive data and Calculate the mean, max, median, and sem of the accuracy data frame by aggregating over the 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n  mean_accuracy  max_accuracy  median_accuracy  std_error   std_dev  \\\n",
      "0  1       0.653448      0.689655         0.659483   0.009770  0.030896   \n",
      "1  2       0.641379      0.681034         0.642241   0.008348  0.026399   \n",
      "\n",
      "    med_q25   med_q75  \n",
      "0  0.633621  0.672414  \n",
      "1  0.637931  0.659483  \n"
     ]
    }
   ],
   "source": [
    "accuracy_df = tmpresults_df.loc[tmpresults_df['expert_match?']=='yes']\n",
    "\n",
    "mean_accuracy = accuracy_df.groupby(['n']).ratios.mean().reset_index(name='mean_accuracy')\n",
    "max_accuracy = accuracy_df.groupby(['n']).ratios.max().reset_index(name='max_accuracy')\n",
    "median_accuracy = accuracy_df.groupby(['n']).ratios.median().reset_index(name='median_accuracy')\n",
    "median_q25 = accuracy_df.groupby(['n']).ratios.quantile(0.25).reset_index(name='med_q25')\n",
    "median_q75 = accuracy_df.groupby(['n']).ratios.quantile(0.75).reset_index(name='med_q75')\n",
    "mean_error = accuracy_df.groupby(['n']).ratios.sem().reset_index(name='std_error')\n",
    "mean_dev = accuracy_df.groupby(['n']).ratios.std().reset_index(name='std_dev')\n",
    "    \n",
    "stats_result = mean_accuracy.merge(max_accuracy.merge(median_accuracy.merge(mean_error.merge(mean_dev.merge(median_q25.merge(median_q75, on=(['n']), how='left'), on=(['n']), how='left'), on=(['n']), how='left'), on=(['n']), how='left'), on=(['n']), how='left'), on=(['n']), how='left')\n",
    "print(stats_result.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot of mean and standard deviation\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f46e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"plot of mean and standard deviation\")\n",
    "plot_it = stats_result[['mean_accuracy','n','std_dev']].copy()\n",
    "mplot.figure()\n",
    "mplot.xlabel(\"number of workers (n)\")\n",
    "mplot.ylabel(\"Accuracy\")\n",
    "mplot.ylim(0.55, 0.8)\n",
    "mplot.errorbar(x='n',y='mean_accuracy', yerr='std_dev', data=plot_it, linestyle='-', marker='o')\n",
    "mplot.title(\"Number of workers vs accuracy\")\n",
    "mplot.show()\n",
    "#mplot.savefig(exppath+'mean_accuracy_sd_dev_lg_font.png', bbox_inches='tight', dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot of median and q25 and q75 quantiles\n"
     ]
    }
   ],
   "source": [
    "print(\"plot of median and q25 and q75 quantiles\")\n",
    "plot_it = stats_result[['median_accuracy','n','med_q25','med_q75']].copy()\n",
    "qt_err=numpy.array([stats_result['median_accuracy']-stats_result['med_q25'],stats_result['med_q75']-stats_result['median_accuracy']])\n",
    "mplot.figure()\n",
    "mplot.xlabel(\"number of workers (n)\", fontsize=18)\n",
    "mplot.ylabel(\"Accuracy\", fontsize=18)\n",
    "mplot.ylim(0.55, 0.80)\n",
    "mplot.errorbar(x='n',y='median_accuracy', yerr=qt_err, data=plot_it, linestyle='-', marker='o')\n",
    "mplot.title(\"Number of workers vs accuracy\", fontsize=18)\n",
    "mplot.tick_params(axis='both', which='major', labelsize=20)\n",
    "mplot.show()\n",
    "#mplot.savefig(exppath+'median_accuracy_quantiles_lg_font.png', bbox_inches='tight', dpi=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly subsample the user annotations to determine how voting threshold (k) relates to agreement with the quality-checked results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "k=1\n",
    "majority_response_k=[]\n",
    "\n",
    "k=1\n",
    "while k<16:\n",
    "    i=0\n",
    "    while i<10:\n",
    "        for each_cpmid in test_set_cpmids:\n",
    "            result_dict = {}\n",
    "            result_dict['iteration'] = i\n",
    "            result_dict['cpmid'] = each_cpmid\n",
    "            result_dict['k'] = k\n",
    "            tmp_df = total_ref_set.loc[total_ref_set['cpmid']==each_cpmid]\n",
    "            user_set = set(tmp_df['user_id'].tolist())\n",
    "            if k<=len(user_set):\n",
    "                user_sample = random.sample(user_set, k)\n",
    "                ref_sample = tmp_df.loc[tmp_df['user_id'].isin(user_sample)]\n",
    "                if k == 1:\n",
    "                    result_dict['response'] = ref_sample.iloc[0]['evtype']\n",
    "                    result_dict['majority?'] = 'yes'\n",
    "                    result_dict['tie?'] = 'no'\n",
    "                    result_dict['result_selection'] = 'single_vote'\n",
    "                else:\n",
    "                    ## Groupby response and get biggest kvalue    \n",
    "                    ref_sample_size = ref_sample.groupby(['cpmid','evtype']).size().reset_index(name='counts')\n",
    "                    ref_sample_size.sort_values('counts', ascending=False, inplace=True)\n",
    "                    first_most = ref_sample_size.iloc[0]['counts']\n",
    "                    try:\n",
    "                        sec_most = ref_sample_size.iloc[1]['counts'] ##if this works, results are not unanimous\n",
    "                        result_dict['majority?'] = 'n/a'\n",
    "                        result_dict['response'] = 'not_enough'\n",
    "                        result_dict['tie?'] = 'n/a'\n",
    "                        result_dict['result_selection'] = 'n/a' \n",
    "                    except: ## Scenario: results are unanimous\n",
    "                        result_dict['majority?'] = 'unanimous'\n",
    "                        result_dict['response'] = ref_sample_size.iloc[0]['evtype']\n",
    "                        result_dict['tie?'] = 'no'\n",
    "                        result_dict['result_selection'] = 'majority'\n",
    "            else:\n",
    "                result_dict['majority?'] = 'n/a'\n",
    "                result_dict['response'] = 'not_enough'\n",
    "                result_dict['tie?'] = 'n/a'\n",
    "                result_dict['result_selection'] = 'n/a' \n",
    "            ## check how well user response matched expert response\n",
    "            tmp_edf = esample_df.loc[esample_df['cpmid']==each_cpmid]           \n",
    "            test_response = result_dict.get('response')\n",
    "            expert_response = tmp_edf['conclusion'].iloc[0]\n",
    "            if test_response=='not_enough':\n",
    "                result_dict['expert_match?'] = 'n/a'\n",
    "            elif test_response == expert_response:\n",
    "                result_dict['expert_match?'] = 'yes'\n",
    "            else:\n",
    "                result_dict['expert_match?'] = 'no'\n",
    "            majority_response_k.append(result_dict) \n",
    "        i=i+1\n",
    "    k=k+1\n",
    "   \n",
    "\n",
    "majority_df_k = pandas.DataFrame(majority_response_k)\n",
    "\n",
    "print(majority_df_k.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#majority_df_k.to_csv(exppath+'raw_random_k_accuracy_results.txt',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the resulting data, grouping by iteration and threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of expert_match (true positive) vs total number of responses (true positive plus incorrect response) \n",
    "This gives total number of answers that matched vs didn't match the QC'd result for the whole QC cpmid set at every level of n, for each repetition and iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_matrix_less_missing_k = majority_df_k.loc[majority_df_k['expert_match?']!='n/a']\n",
    "response_matrix_k = response_matrix_less_missing_k.groupby(['iteration','k','expert_match?']).size().reset_index(name='counts')\n",
    "print(response_matrix_k.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the n/a responses (this is usually when n exceeds sample due to removal of tester account data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_captured_k = response_matrix_less_missing_k.groupby(['k','iteration']).size().reset_index(name='totals')\n",
    "print(total_captured_k.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge tables to be able to do calculations and obtain total attempts, then calculate accuracy (True Positive/Total) and inaccuracy (Incorrect Response/Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(response_matrix_less_missing.head(n=2))\n",
    "tmpresults_df_k = response_matrix_k.merge(total_captured_k,on=(['k','iteration']), how=\"inner\")\n",
    "tmpresults_df_k['ratios'] = tmpresults_df_k['counts']/tmpresults_df_k['totals']\n",
    "tmpresults_df_k['dropped'] = 116-tmpresults_df_k['totals'].astype(int)\n",
    "print(tmpresults_df_k.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since accuracy only counts true positives and total attempts, keep only the true positive data and Calculate the mean, max, median, and sem of the accuracy data frame by aggregating over the 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaccuracy_df = tmpresults_df_k.loc[tmpresults_df_k['expert_match?']=='yes']\n",
    "print(kaccuracy_df.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmean_accuracy = kaccuracy_df.groupby(['k']).ratios.mean().reset_index(name='mean_accuracy')\n",
    "kmax_accuracy = kaccuracy_df.groupby(['k']).ratios.max().reset_index(name='max_accuracy')\n",
    "kmedian_accuracy = kaccuracy_df.groupby(['k']).ratios.median().reset_index(name='median_accuracy')\n",
    "kmedian_q25 = kaccuracy_df.groupby(['k']).ratios.quantile(0.25).reset_index(name='med_q25')\n",
    "kmedian_q75 = kaccuracy_df.groupby(['k']).ratios.quantile(0.75).reset_index(name='med_q75')\n",
    "kmean_error = kaccuracy_df.groupby(['k']).ratios.sem().reset_index(name='std_error')\n",
    "kmean_dev = kaccuracy_df.groupby(['k']).ratios.std().reset_index(name='std_dev')\n",
    "\n",
    "ksample_dev = kaccuracy_df.groupby(['k']).totals.std().reset_index(name='samp_dev')\n",
    "kmean_totals = kaccuracy_df.groupby(['k']).totals.mean().reset_index(name='mean_samples')\n",
    "    \n",
    "kstats_result = kmean_accuracy.merge(kmax_accuracy.merge(kmedian_accuracy.merge(kmean_error.merge(kmean_dev.merge(kmedian_q25.merge(kmedian_q75, on=(['k']), how='left'), on=(['k']), how='left'), on=(['k']), how='left'), on=(['k']), how='left'), on=(['k']), how='left'), on=(['k']), how='left')\n",
    "kstats_result2= kmean_totals.merge(ksample_dev, on=('k'),how='left')\n",
    "print(stats_result.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_it = kstats_result[['mean_accuracy','k','std_dev']].copy()\n",
    "mplot.figure()\n",
    "mplot.xlabel(\"k\")\n",
    "mplot.ylabel(\"Accuracy\")\n",
    "mplot.ylim(0,1)\n",
    "mplot.errorbar(x='k',y='mean_accuracy', yerr='std_dev', data=plot_it, linestyle='-', marker='o')\n",
    "mplot.title(\"Voter threshold vs accuracy\")\n",
    "mplot.show()\n",
    "#mplot.savefig(exppath+'votingthresh_accuracy.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = kstats_result[['mean_accuracy','k','std_dev']].copy()\n",
    "data2 = kstats_result2[['mean_samples','k','samp_dev']].copy()\n",
    "\n",
    "fig, ax1 = mplot.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('k')\n",
    "ax1.set_ylabel('Accuracy', color=color)\n",
    "ax1.errorbar(x=data1['k'], y=data1['mean_accuracy'],yerr=data1['std_dev'], color=color, linestyle='-', marker='o')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax1.set_ylim(0, 1)\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.set_ylim(0, 120)\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('samples counted', color=color)  # we already handled the x-label with ax1\n",
    "ax2.errorbar(x=data2['k'], y=data2['mean_samples'],yerr=data2['samp_dev'], color=color, linestyle='-', marker='o')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "mplot.show()\n",
    "#mplot.savefig(exppath+'votingthresh_accuracy_docs.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
