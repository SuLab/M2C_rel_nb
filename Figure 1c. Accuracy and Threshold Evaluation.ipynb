{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Relationship Annotation Accuracy Based on a QC'd Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the evaluation of user annotations in comparison of the randomly sampled set of completed tasks that have been manually annotated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import modules and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import m2c_rel_basic\n",
    "import relationship_dictionaries\n",
    "import random\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as mplot\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the relationship annotations data for only completed concept pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savepath = 'data/'\n",
    "exppath = 'results/'\n",
    "all_completed_anns = read_csv(exppath+'all_completed_anns.txt', delimiter='\\t', header=0)\n",
    "all_completed_anns.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Quality Curated Sample Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "esample_df = m2c_rel_basic.get_QC_data(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dictionaries for translating hashed responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_hash_dict,redundant_response_dict,abbreviated_rels_dict,abbreviated_rels_dict_4_hash,concept_broken_dict,concept_not_broken_dict = relationship_dictionaries.load_RE_dictionaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the user annotations relative to the quality curated annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pull the annotations marked 'broken' during QC'ing into a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_broken = esample_df.loc[esample_df['conclusion']=='concept_broken']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pull the cpmids (concept pair pmid hashed identifiers) that were QC'd into a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expert_cpmids = set(esample_df['cpmid'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cpmids from the set of annotations that were QC'd and use the cpmids from the QC'd set to pull all user annotations for the same cpmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_cpmids = set(expert_cpmids)\n",
    "total_ref_set = all_completed_anns.loc[all_completed_anns['cpmid'].isin(test_set_cpmids)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviate the user responses for ease of viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_ref_set['evtype'].replace(abbreviated_rels_dict_4_hash, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove distinction between C1 broken and C2 broken since it's technically possible for both to be true AND because it's not important to distinguish it in this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   kind             ann_date  user_id         evtype reltype      pmid  \\\n",
      "8    re  2016-05-24 06:54:49      364  g_unrelated_d     g_d  11353896   \n",
      "14   re  2016-05-24 07:23:43      364   g_mutation_d     g_d  16970037   \n",
      "\n",
      "        concept_created      concept_updated refid1   refid2    concept_pair  \\\n",
      "8   2015-05-21 17:54:48  2015-05-21 17:54:48   4158  D004931  4158_x_D004931   \n",
      "14  2015-05-21 17:54:44  2015-05-21 17:54:44   8086  D009461  8086_x_D009461   \n",
      "\n",
      "   refid1_type refid2_type  user_count  relation_count  test_completions  \\\n",
      "8            g           d        29.0            14.0               1.0   \n",
      "14           g           d        27.0            19.0               3.0   \n",
      "\n",
      "    true_responses  response_ratio                    cpmid  \n",
      "8             28.0        0.500000  11353896_4158_x_D004931  \n",
      "14            24.0        0.791667  16970037_8086_x_D009461  \n"
     ]
    }
   ],
   "source": [
    "total_ref_set['evtype'].replace(concept_broken_dict, inplace=True)\n",
    "esample_df['conclusion'].replace(concept_broken_dict, inplace=True)\n",
    "print(total_ref_set.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly subsample the user annotations to determine how voting threshold (k) relates to agreement with the quality-checked results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the responses and put the results into a dataframe, 10 iterations per k per cpmid. repeat the sampling 5 times to stabilize the results\n",
    "\n",
    "Note that this is the slowest part of the notebook; hence, a print statement has been left in so you know it's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repetition: 0\n",
      "repetition: 1\n",
      "repetition: 2\n",
      "repetition: 3\n",
      "repetition: 4\n",
      "                        cpmid expert_match?  iteration  k majority?  \\\n",
      "0   8006362_D005227_x_D000326           yes          0  1       yes   \n",
      "1     16970037_8086_x_D009422           yes          0  1       yes   \n",
      "2  12882516_C097320_x_D000544            no          0  1       yes   \n",
      "3     21626165_8086_x_D012021            no          0  1       yes   \n",
      "4     16938764_8086_x_D004931           yes          0  1       yes   \n",
      "\n",
      "   repetition        response result_selection tie?  \n",
      "0           0  concept_broken      single_vote   no  \n",
      "1           0    g_mutation_d      single_vote   no  \n",
      "2           0     c_related_d      single_vote   no  \n",
      "3           0   g_unrelated_d      single_vote   no  \n",
      "4           0    g_mutation_d      single_vote   no  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "k=1\n",
    "majority_response=[]\n",
    "j=0\n",
    "\n",
    "while j<5:\n",
    "    i=0\n",
    "    print('repetition:',j)\n",
    "    while i<10:\n",
    "        k=1\n",
    "        while k<16:\n",
    "            for each_cpmid in test_set_cpmids:\n",
    "                result_dict = {}\n",
    "                result_dict['repetition'] = j\n",
    "                result_dict['iteration'] = i\n",
    "                result_dict['cpmid'] = each_cpmid\n",
    "                result_dict['k'] = k\n",
    "                tmp_df = total_ref_set.loc[total_ref_set['cpmid']==each_cpmid]\n",
    "                user_set = set(tmp_df['user_id'].tolist())\n",
    "                if k<=len(user_set):\n",
    "                    user_sample = random.sample(user_set, k)\n",
    "                    ref_sample = tmp_df.loc[tmp_df['user_id'].isin(user_sample)]\n",
    "                    if k == 1:\n",
    "                        result_dict['response'] = ref_sample.iloc[0]['evtype']\n",
    "                        result_dict['majority?'] = 'yes'\n",
    "                        result_dict['tie?'] = 'no'\n",
    "                        result_dict['result_selection'] = 'single_vote'\n",
    "                    else:\n",
    "                        ## Groupby response and get biggest and next biggest value    \n",
    "                        ref_sample_size = ref_sample.groupby(['cpmid','evtype']).size().reset_index(name='counts')\n",
    "                        ref_sample_size.sort_values('counts', ascending=False, inplace=True)\n",
    "                        first_most = ref_sample_size.iloc[0]['counts']\n",
    "                        try:\n",
    "                            sec_most = ref_sample_size.iloc[1]['counts'] ##if this works, results are not unanimous\n",
    "                            if first_most > sec_most: ## If there is a majority\n",
    "                                result_dict['majority?'] = 'simple_majority'\n",
    "                                result_dict['result_selection'] = 'majority'\n",
    "                                result_dict['response'] = ref_sample_size.iloc[0]['evtype']\n",
    "                                result_dict['tie?'] = 'no'\n",
    "                            else: ## else it's a tie\n",
    "                                result_dict['majority?'] = 'no_majority'\n",
    "                                result_dict['result_selection'] = 'random'\n",
    "                                if len(ref_sample_size)==2: ## check if full tie\n",
    "                                    rand_option = random.randint(0, 1)\n",
    "                                    result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                    result_dict['tie?'] = 'two_way'\n",
    "                                elif (len(ref_sample_size) > 2) & (sec_most > ref_sample_size.iloc[3]['counts']): #check if majority tied\n",
    "                                    rand_option = random.randint(0, 1)\n",
    "                                    result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                    result_dict['tie?'] = 'top_two_way'\n",
    "                                elif (len(ref_sample_size) > 2) & (sec_most == ref_sample_size.iloc[3]['counts']): #check for 3-way tie                      \n",
    "                                    rand_option = random.randint(0, 2)\n",
    "                                    result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                    result_dict['tie?'] = '3_way'\n",
    "                                else:    \n",
    "                                    rand_option = random.randint(0, len(ref_sample_size))\n",
    "                                    result_dict['response'] = ref_sample_size.iloc[rand_option]['evtype']\n",
    "                                    result_dict['tie?'] = 'other'\n",
    "                        except: ## Scenario: results are unanimous\n",
    "                            result_dict['majority?'] = 'unanimous'\n",
    "                            result_dict['response'] = ref_sample_size.iloc[0]['evtype']\n",
    "                            result_dict['tie?'] = 'no'\n",
    "                            result_dict['result_selection'] = 'majority'\n",
    "                else:\n",
    "                    result_dict['majority?'] = 'n/a'\n",
    "                    result_dict['response'] = 'not_enough'\n",
    "                    result_dict['tie?'] = 'n/a'\n",
    "                    result_dict['result_selection'] = 'n/a' \n",
    "                ## check how well user response matched expert response\n",
    "                tmp_edf = esample_df.loc[esample_df['cpmid']==each_cpmid]           \n",
    "                test_response = result_dict.get('response')\n",
    "                expert_response = tmp_edf['conclusion'].iloc[0]\n",
    "                if test_response=='not_enough':\n",
    "                    result_dict['expert_match?'] = 'n/a'\n",
    "                elif test_response == expert_response:\n",
    "                    result_dict['expert_match?'] = 'yes'\n",
    "                else:\n",
    "                    result_dict['expert_match?'] = 'no'\n",
    "                majority_response.append(result_dict) \n",
    "            k = k+1\n",
    "        i=i+1\n",
    "    j=j+1\n",
    "    \n",
    "\n",
    "majority_df = pandas.DataFrame(majority_response)\n",
    "\n",
    "print(majority_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the resulting data, grouping by iteration and threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of expert_match (true positive) vs total number of responses (true positive plus incorrect response) \n",
    "This gives total number of answers that matched vs didn't match the QC'd result for the whole QC cpmid set at every level of k, for each repetition and iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response_matrix = majority_df.groupby(['repetition','iteration','k','expert_match?']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the n/a responses (this is usually when k exceeds sample due to removal of tester account data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response_matrix_less_missing = response_matrix.loc[response_matrix['expert_match?']!='n/a']\n",
    "total_captured = response_matrix_less_missing.groupby(['repetition','iteration','k'])['counts'].sum().reset_index(name='totals')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge tables to be able to do calculations and obtain total attempts, then calculate accuracy (True Positive/Total) and inaccuracy (Incorrect Response/Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmpresults_df = response_matrix.merge(total_captured,on=(['repetition','iteration','k']))\n",
    "tmpresults_df['ratios'] = tmpresults_df['counts']/tmpresults_df['totals']\n",
    "#print(tmpresults_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since accuracy only counts true positives and total attempts, keep only the true positive data and Calculate the mean, max, median, and sem of the accuracy data frame by aggregating over the 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   repetition  k  avg_accuracy  max_accuracy  median_accuracy  std_error\n",
      "0           0  1      0.637069      0.698276         0.637931   0.011088\n",
      "1           0  2      0.644828      0.681034         0.659483   0.010813\n"
     ]
    }
   ],
   "source": [
    "accuracy_df = tmpresults_df.loc[tmpresults_df['expert_match?']=='yes']\n",
    "\n",
    "mean_accuracy = accuracy_df.groupby(['repetition','k']).ratios.mean().reset_index(name='avg_accuracy')\n",
    "max_accuracy = accuracy_df.groupby(['repetition','k']).ratios.max().reset_index(name='max_accuracy')\n",
    "median_accuracy = accuracy_df.groupby(['repetition','k']).ratios.median().reset_index(name='median_accuracy')\n",
    "mean_error = accuracy_df.groupby(['repetition','k']).ratios.sem().reset_index(name='std_error')\n",
    "    \n",
    "stats_result = mean_accuracy.merge(max_accuracy.merge(median_accuracy.merge(mean_error, on=(['repetition','k']), how='left'), on=(['repetition','k']), how='left'), on=(['repetition','k']), how='left')\n",
    "print(stats_result.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since max_accuracy is not any sort of average and can vary greatly, aggregate across the 5 repetitions and calculate mean, median, max of the mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k  mean_avg_accuracy  mean_max_accuracy  mean_median_accuracy  \\\n",
      "0  1           0.635517           0.698276              0.634483   \n",
      "1  2           0.642069           0.689655              0.643966   \n",
      "\n",
      "   mean_std_error  mean_max_std_error  mean_median_std_error  \n",
      "0        0.002759            0.007711               0.003708  \n",
      "1        0.002606            0.007711               0.005553  \n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = stats_result.groupby('k').avg_accuracy.mean().reset_index(name='mean_avg_accuracy')\n",
    "max_accuracy = stats_result.groupby('k').max_accuracy.mean().reset_index(name='mean_max_accuracy')\n",
    "median_accuracy = stats_result.groupby('k').median_accuracy.mean().reset_index(name='mean_median_accuracy')\n",
    "\n",
    "## aggregate across the 5 repetitions and calculate standard error for mean, max, and median accuracy\n",
    "mean_error1 = stats_result.groupby('k').avg_accuracy.sem().reset_index(name='mean_std_error')\n",
    "mean_error2 = stats_result.groupby('k').max_accuracy.sem().reset_index(name='mean_max_std_error')\n",
    "mean_error3 = stats_result.groupby('k').median_accuracy.sem().reset_index(name='mean_median_std_error')\n",
    "\n",
    "mean_error =  mean_error1.merge(mean_error2.merge(mean_error3, on='k', how='left'), on='k', how='left')\n",
    "   \n",
    "stats_result2 = mean_accuracy.merge(max_accuracy.merge(median_accuracy.merge(mean_error, on='k', how='left'), on='k', how='left'), on='k', how='left')\n",
    "print(stats_result2.head(n=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Export results\n",
    "stats_result2.to_csv(exppath+\"fig1c_data.txt\", sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6ae8978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_it = stats_result2[['mean_avg_accuracy','k','mean_std_error']].copy()\n",
    "mplot.figure()\n",
    "mplot.xlabel(\"k\")\n",
    "mplot.ylabel(\"Accuracy\")\n",
    "mplot.ylim(0.55, 0.80)\n",
    "mplot.errorbar(x='k',y='mean_avg_accuracy', yerr='mean_std_error', data=plot_it, linestyle='-', marker='o')\n",
    "mplot.title(\"Voter threshold vs accuracy\")\n",
    "mplot.show()\n",
    "#mplot.savefig(exppath+'votingthresh_accuracy.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
